[encoder]
n_layer = 24
n_head = 32
hidden_size = 2048 
ffn_hidden_size = 5120
vocab_size = 32128
n_positions = 512
has_position_embedding = False
has_token_type_embedding = False
has_embedding_layernorm = False
has_embedding_scale = False
q_scaling = 0.125
has_attention_qkvo_bias = False
has_mlp_bias = False
has_model_final_layernorm = True
layernorm_eps = 1e-6
layernorm_position = pre_layernorm
layernorm_type = RmsNorm
hidden_act = gelu_new
relative_attention = True
num_buckets = 32
max_distance = 128
storage_dtype = float32

[decoder]
n_layer = 24
n_head = 32
hidden_size = 2048
ffn_hidden_size = 5120
vocab_size = 32128
n_positions = 512
has_position_embedding = False
has_token_type_embedding = False
has_embedding_layernorm = False
has_embedding_scale = False
q_scaling = 0.125
has_attention_qkvo_bias = False
has_mlp_bias = False
has_model_final_layernorm = True
layernorm_eps = 1e-6
layernorm_position = pre_layernorm
layernorm_type = RmsNorm
hidden_act = gelu_new
has_lm_head_bias = False
relative_attention = True
num_buckets = 32
max_distance = 128
storage_dtype = float32
